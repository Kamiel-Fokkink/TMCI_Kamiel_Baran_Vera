{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from nltk.util import ngrams\n",
    "from sys import platform\n",
    "\n",
    "\n",
    "# To make sure the folder standards work in windows and other systems\n",
    "if platform == \"win32\":\n",
    "    # Windows...\n",
    "    folder_separator = \"\\\\\"\n",
    "else:\n",
    "    folder_separator = \"/\"\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "MAX_LENGTH = 16 # This depends on the length of sentences in our sample set, it makes sure the set of weights for the\n",
    "                # attention decoder has the right length.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To represent our words as vectors, we use one-hot encoding. Each word is then a large vector full of zeroes, with a one in the position of the word. The size of the vector is the length of the vocabulary. The following helper class creates a Lang object, which is useful for making our one-hot encoded word vectors. The Lang object contains two dictionaries: a word2index dictionary that has each word of our vocabulary as keys, and its index in the vector as value. The other dictionary is index2word, which does the same but is reversed. It also keeps track of how many words we have, in a word2count dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then make two Lang classes from our dataset. The Lang class stores useful information about the words and indexes in our one-hot encoded vector. We use these classes for training. The input language is going to be English, and the output language will be Dutch. Also, in this step each input sentence is reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def lang_class_maker(data, lang1, lang2):\n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "    \n",
    "    for pair in data:\n",
    "        # The sentence is splitted, reversed, and reassembled\n",
    "        input_sentence = \" \".join(pair[0].split()[::-1])\n",
    "        input_lang.addSentence(input_sentence)\n",
    "        output_lang.addSentence(pair[1])\n",
    "        \n",
    "    return input_lang, output_lang\n",
    "\n",
    "def lang_class_updater(data, input_lang, output_lang):\n",
    "    for pair in data:\n",
    "        # The sentence is splitted, reversed, and reassembled\n",
    "        input_sentence = \" \".join(pair[0].split()[::-1])\n",
    "        input_lang.addSentence(input_sentence)\n",
    "        output_lang.addSentence(pair[1])\n",
    "        \n",
    "    return input_lang, output_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below follow the encoder, decoder and attention decoder classes, as described by the [Pytorch tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the following helper functions for our training. When given a pair of sentences, we want to make two tensors from them, containing the indexes of each word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    total = list()\n",
    "    for word in sentence.split(\" \"):\n",
    "        try:\n",
    "            total.append(lang.word2index[word])\n",
    "        except:\n",
    "            print(f\"This is the word: {word}\")\n",
    "            raise Exception(\"We fucked up, and its a key error\")\n",
    "    return total\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two functions are very useful for the human operator at the computer. The first one shows a plot with the cost per amount of iterations, which helps with determining how fast the model improves, and gives an indication of how many iterations we should use. The second one calculates the amount of time that went by, and the amount of time left until the training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are finally ready for training, which we will do with the following two functions. The first one trains for one sentence pair. The second one iterates a certain amount of times, and trains one pair of sentences in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    # Use its own predictions as the next input\n",
    "    for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can put the different tweaks to the models. The first one is to use teacher forcing. This basically uses the target sentence (given from the data) as input in the Recurrent Neural Network, so the model already knows the target sentence and tries to approximate this. The teacher forcing ratio can be specified in the input, and is a number between 0 and 1, indicating in how much of the cases we will apply teacher forcing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def train_teacher(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, \n",
    "                  max_length=MAX_LENGTH, teacher_forcing_ratio=0.5):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, pairs, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(pairs[i]) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train_teacher(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    #showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model has been trained, we also want to be able to test what it's output is. The following function takes the trained encoder and decoder, and an English sentence as input, and produces a Dutch translation as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def bleu_text(target_text: list, reference_text: list, n_precision = 4, smoothing = 0):\n",
    "    \"\"\"takes a target_text, and a reference_text, of the same length, as lists within lists, where each inner list is a\n",
    "    tokenized sentence, n_precision, which determines up to which n-gram the bleu value is computed, and a possible\n",
    "    smoothing\"\"\"\n",
    "    temp = np.zeros((n_precision, 2)) #each row is an n(-gram), column 0 is counted matches, column 1 is total n-grams\n",
    "    for i in range(0, len(target_text)):\n",
    "        for j in range(0, n_precision):\n",
    "            count = 0\n",
    "            target = list(ngrams(target_text[i], j+1))\n",
    "            reference = list(ngrams(reference_text[i], j+1))\n",
    "            for x in target:\n",
    "                #to make sure no n-gram is used as a match twice, it is removed from the reference list\n",
    "                if x in reference:\n",
    "                    reference.remove(x)\n",
    "                    count += 1\n",
    "            #if a smoothing is specified, and for a certain n-gram 0 counts were found, it is smoothed over\n",
    "            if smoothing != 0 and count == 0:\n",
    "                count = smoothing\n",
    "            temp[j] += [count, len(target)]\n",
    "    #the amount of matches will be divided by the total amount of n-grams\n",
    "    result = temp[:,0]/temp[:,1]\n",
    "    #the final result will be the geometric mean of the different n-gram results\n",
    "    return result.prod()**(1/len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Constants depending on the input\n",
    "VERBOSE = False\n",
    "HIDDEN_LAYER_SIZE = 256\n",
    "PRINT_AT_MOST = 3\n",
    "TOTAL_CHUNK_NUMBER = 53542\n",
    "CHECK_EVERY_PERCENT = 5\n",
    "TRAINING_CHUNK_NUMBER = TOTAL_CHUNK_NUMBER // (10/8)\n",
    "TEST_CHUNK_NUMBER = TOTAL_CHUNK_NUMBER - TRAINING_CHUNK_NUMBER\n",
    "pickle_off = f\"data{folder_separator}final_sample.pkl\"\n",
    "file_stream = (open(pickle_off, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Variables\n",
    "language_model_chunks = TOTAL_CHUNK_NUMBER\n",
    "model_initialized = False\n",
    "percent_limit = CHECK_EVERY_PERCENT\n",
    "\n",
    "print(\"Preparing Lang class...\")\n",
    "while language_model_chunks:\n",
    "    try:\n",
    "        pairs = pickle.load(file_stream)\n",
    "        # If model is initialized, keep adding to it\n",
    "        if model_initialized:\n",
    "            input_lang, output_lang = lang_class_updater(pairs, input_lang, output_lang)\n",
    "            percent = (1-(language_model_chunks/TOTAL_CHUNK_NUMBER)) * 100\n",
    "            if percent > percent_limit:\n",
    "                print(f'{percent:.2f} % vocabulary building is done')\n",
    "                percent_limit += CHECK_EVERY_PERCENT\n",
    "        # Else initialize the model\n",
    "        else:\n",
    "            input_lang, output_lang = lang_class_maker(pairs, 'en', 'nl')\n",
    "            model_initialized = True\n",
    "    except EOFError:\n",
    "        raise Exception(\"You have reached the end of chunks\")\n",
    "    language_model_chunks -= 1\n",
    "\n",
    "\n",
    "print(f\"Input size: {input_lang.n_words}\\nOutput size: {output_lang.n_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh the filestream\n",
    "file_stream.close()\n",
    "file_stream = (open(pickle_off, \"rb\"))\n",
    "\n",
    "# Variable initialization\n",
    "model_initialized = False\n",
    "training_chunk_num = TRAINING_CHUNK_NUMBER\n",
    "training_iteration_ratio = 10\n",
    "percent_limit = CHECK_EVERY_PERCENT\n",
    "\n",
    "print(\"En/De coding...\")\n",
    "encoder1 = EncoderRNN(input_lang.n_words, HIDDEN_LAYER_SIZE).to(device)\n",
    "attndecoder1 = AttnDecoderRNN(HIDDEN_LAYER_SIZE, output_lang.n_words).to(device)\n",
    "\n",
    "print(\"Training...\")\n",
    "while training_chunk_num:\n",
    "    try:\n",
    "        # Read the pickle manually, to keep track of the stream\n",
    "        pairs = pickle.load(file_stream)\n",
    "        random.shuffle(pairs)  \n",
    "\n",
    "        # Load the previous states if its already initialized\n",
    "        if model_initialized:            \n",
    "            # To show progress, we can evaluate each step with the next chunk before using\n",
    "            # it on training\n",
    "            to_be_evaluated=[[],[]]\n",
    "\n",
    "            if VERBOSE:\n",
    "                for pair in pairs:\n",
    "                    to_be_evaluated[0].append(evaluate(encoder1, attndecoder1, pair[0]))\n",
    "                    to_be_evaluated[1].append(pair[1].split(' '))\n",
    "\n",
    "                for i in range(min(len(to_be_evaluated[0]), PRINT_AT_MOST)):\n",
    "                    print((to_be_evaluated[0][i], to_be_evaluated[1][i]))\n",
    "\n",
    "                print(bleu_text(to_be_evaluated[0], to_be_evaluated[1]))\n",
    "        else:\n",
    "            model_initialized = True\n",
    "\n",
    "        # This actually trains the model. The good part about this is that you can interrupt or stop it for a bit, and run it again\n",
    "        # later, to continue the same training.\n",
    "        \n",
    "        trainIters(encoder1, attndecoder1, pairs, (len(pairs)//training_iteration_ratio), print_every=200)\n",
    "        \n",
    "        # To save the model in each iteration\n",
    "        torch.save(encoder1.state_dict(), f'models{folder_separator}model1encoder_state.pt')\n",
    "        torch.save(attndecoder1.state_dict(), f'models{folder_separator}model1attn_decoder_state.pt')\n",
    "        \n",
    "        chunk_size_file = open(f'models{folder_separator}current_chunk.txt', 'w')\n",
    "        chunk_size_file.write(str(training_chunk_num))\n",
    "        chunk_size_file.close()\n",
    "        \n",
    "        percent = (1-(training_chunk_num/TRAINING_CHUNK_NUMBER)) *100\n",
    "        if percent > percent_limit:\n",
    "                print(f'{percent:.2f} % training is done')\n",
    "                percent_limit += CHECK_EVERY_PERCENT\n",
    "        \n",
    "        training_chunk_num -= 1\n",
    "    # This exception shows when the set is not divided to the exact number of expected chunks\n",
    "    except EOFError:\n",
    "        raise Exception(\"You have reached the end of chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for evaluation\n",
    "percent_limit = CHECK_EVERY_PERCENT\n",
    "test_chunk_num = TEST_CHUNK_NUMBER\n",
    "to_be_evaluated=[[],[]]\n",
    "\n",
    "while test_chunk_num:\n",
    "    if not encoder1:\n",
    "        encoder1 = torch.load(f'models{folder_separator}model1encoder.pt')\n",
    "        attndecoder1 = torch.load(f'models{folder_separator}model1attn_decoder.pt')\n",
    "    try:\n",
    "        pairs = pickle.load(file_stream)\n",
    "\n",
    "        for pair in pairs:\n",
    "            to_be_evaluated[0].append(pair[1].split(' '))\n",
    "            to_be_evaluated[1].append(evaluate(encoder1, attndecoder1, pair[0]))\n",
    "            \n",
    "        if VERBOSE:\n",
    "            for i in range(min(len(to_be_evaluated[0]), PRINT_AT_MOST)):\n",
    "                print((to_be_evaluated[0][i], to_be_evaluated[1][i]))\n",
    "        \n",
    "        percent = (1-(test_chunk_num/TEST_CHUNK_NUMBER)) *100\n",
    "        if percent > percent_limit:\n",
    "            print(f'{percent:.2f} % testing is done')\n",
    "            percent_limit += CHECK_EVERY_PERCENT\n",
    "        \n",
    "        test_chunk_num -= 1\n",
    "    except EOFError:\n",
    "        raise Exception(\"You have reached the end of chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the scores\n",
    "print(bleu_text(to_be_evaluated[0], to_be_evaluated[1], n_precision = 4))\n",
    "print(bleu_text(to_be_evaluated[0], to_be_evaluated[1], n_precision = 3))\n",
    "print(bleu_text(to_be_evaluated[0], to_be_evaluated[1], n_precision = 2))\n",
    "print(bleu_text(to_be_evaluated[0], to_be_evaluated[1], n_precision = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see example sentences\n",
    "for i in range(min(len(to_be_evaluated[0]), PRINT_AT_MOST)):\n",
    "    print((to_be_evaluated[0][i], to_be_evaluated[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
