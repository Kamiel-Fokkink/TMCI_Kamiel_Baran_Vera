%
% File acl2014.tex
%
% Contact: g.colavizza@uva.nl
%%
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl2014}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{hyperref}

\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\title{Name of your project}

\author{Vera Neplenbroek \\
  {\tt veraneplenbroek@icloud.com} \\\And
  Kamiel Fokkink \\
  {\tt kamielfokkink@gmail.com} \\\And
Baran İşcanlı \\
{\tt barantevitol@gmail.com} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
  The goal of this project is to create a functioning English-Dutch
  translation model. The data set contains English and Dutch
  translations of the same movie subtitles, which will be connected
  in the translation model to build the translator. The model
  consists of two Recurrent Neural Networks, an Encoder and a Decoder,
  which will transform the English input sentence to a tensor, and
  then to a Dutch output sentence. It is based on a PyTorch
  implementation, but extended by reversing the input sentences, and
  using different data formats. Evaluation will be done using the
  BLEU measure, giving each translated Dutch sentence/text a score
  out of 1, based on how much it corresponds to the target sentence/text.
\end{abstract}

\section{Introduction}

Reports must be maximum 4-page long, excluding references.

\section{General Instructions}

Manuscripts must be in two-column format.  Exceptions to the
two-column format include the title, authors' names and complete
addresses, which must be centered at the top of the first page, and
any full-width figures or tables (see the guidelines in
Subsection~\ref{ssec:first}). {\bf Type single-spaced.}  Start all
pages directly under the top margin. See the guidelines later
regarding formatting the first page.

\subsection{Format of Electronic Manuscript}
\label{sect:pdf}

For the production of the electronic manuscript you must use Adobe's
Portable Document Format (PDF). PDF files are usually produced from
\LaTeX\ using the \textit{pdflatex} command. If your version of
\LaTeX\ produces Postscript files, you can convert these into PDF
using \textit{ps2pdf} or \textit{dvipdf}. On Windows, you can also use
Adobe Distiller to generate PDF.

Please make sure that your PDF file includes all the necessary fonts
(especially tree diagrams, symbols, and fonts with Asian
characters). When you print or create the PDF file, there is usually
an option in your printer setup to include none, all or just
non-standard fonts.  Please make sure that you select the option of
including ALL the fonts. \textbf{Before sending it, test your PDF by
  printing it from a computer different from the one where it was
  created.} Moreover, some word processors may generate very large PDF
files, where each page is rendered as an image. Such images may
reproduce poorly. In this case, try alternative ways to obtain the
PDF. One way on some systems is to install a driver for a postscript
printer, send your document to the printer specifying ``Output to a
file'', then convert the file to PDF.

It is of utmost importance to specify the \textbf{A4 format} (21 cm
x 29.7 cm) when formatting the report. When working with
{\tt dvips}, for instance, one should specify {\tt -t a4}.

Print-outs of the PDF file on A4 report should be identical to the
hardcopy version.


\subsection{Layout}
\label{ssec:layout}

Format manuscripts two columns to a page, in the manner these
instructions are formatted. The exact dimensions for a page on A4
report are:

\begin{itemize}
\item Left and right margins: 2.5 cm
\item Top margin: 2.5 cm
\item Bottom margin: 2.5 cm
\item Column width: 7.7 cm
\item Column height: 24.7 cm
\item Gap between columns: 0.6 cm
\end{itemize}

\noindent Papers should not be submitted on any other report size, no exceptions.


\subsection{Fonts}

For reasons of uniformity, Adobe's {\bf Times Roman} font should be
used. In \LaTeX2e{} this is accomplished by putting

\begin{quote}
\begin{verbatim}
\usepackage{times}
\usepackage{latexsym}
\end{verbatim}
\end{quote}
in the preamble. If Times Roman is unavailable, use {\bf Computer
  Modern Roman} (\LaTeX2e{}'s default).  Note that the latter is about
  10\% less dense than Adobe's Times Roman font.


\begin{table}[h]
\begin{center}
\begin{tabular}{|l|rl|}
\hline \bf Type of Text & \bf Font Size & \bf Style \\ \hline
report title & 15 pt & bold \\
author names & 12 pt & bold \\
the word ``Abstract'' & 12 pt & bold \\
section titles & 12 pt & bold \\
document text & 11 pt  &\\
captions & 11 pt & \\
abstract text & 10 pt & \\
bibliography & 10 pt & \\
footnotes & 9 pt & \\
\hline
\end{tabular}
\end{center}
\caption{\label{font-table} Font guide.}
\end{table}

\subsection{The First Page}
\label{ssec:first}

Center the title and author's name(s) across both
columns. Do not use footnotes for affiliations. Use the
two-column format only when you begin the abstract.

{\bf Title}: Place the title centered at the top of the first page, in
a 15-point bold font. (For a complete guide to font sizes and styles,
see Table~\ref{font-table}) Long titles should be typed on two lines
without a blank line intervening. Approximately, put the title at 2.5
cm from the top of the page, followed by a blank line, then the
author's names(s) on the following line. Do not
use only initials for given names (middle initials are allowed). Do
not format surnames in all capitals (e.g., use ``Schlangen'' not
``SCHLANGEN'').  Do not format title and section headings in all
capitals as well except for proper names (such as ``BLEU'') that are
conventionally in all capitals. Start the body of the first page 7.5 cm from the top of the
page.

{\bf Abstract}: Type the abstract at the beginning of the first
column. The width of the abstract text should be smaller than the
width of the columns for the text in the body of the report by about
0.6 cm on each side. Center the word {\bf Abstract} in a 12 point bold
font above the body of the abstract. The abstract should be a concise
summary of the general thesis and conclusions of the report. It should
be no longer than 150 words. The abstract text should be in 10 point font.

{\bf Text}: Begin typing the main body of the text immediately after
the abstract, observing the two-column format as shown in 
the present document. Do not include page numbers.

{\bf Indent} when starting a new paragraph. Use 11 points for text and 
subsection headings, 12 points for section headings and 15 points for
the title. 

\subsection{Sections}

{\bf Headings}: Type and label section and subsection headings in the
style shown on the present document.  Use numbered sections (Arabic
numerals) in order to facilitate cross references. Number subsections
with the section number and the subsection number separated by a dot,
in Arabic numerals. Do not number subsubsections.

{\bf Citations}: Citations within the text appear in parentheses
as~\cite{Gusfield:97} or, if the author's name appears in the text
itself, as Gusfield~\shortcite{Gusfield:97}.  Append lowercase letters
to the year in cases of ambiguity.  Treat double authors as
in~\cite{Aho:72}, but write as in~\cite{Chandra:81} when more than two
authors are involved. Collapse multiple citations as
in~\cite{Gusfield:97,Aho:72}. Also refrain from using full citations
as sentence constituents. We suggest that instead of
\begin{quote}
  ``\cite{Gusfield:97} showed that ...''
\end{quote}
you use
\begin{quote}
``Gusfield \shortcite{Gusfield:97}   showed that ...''
\end{quote}

If you are using the provided \LaTeX{} and Bib\TeX{} style files, you
can use the command \verb|\newcite| to get ``author (year)'' citations.

\textbf{Please do not use anonymous citations} and do not include
acknowledgements when submitting your reports..

\textbf{References}: Gather the full set of references together under
the heading {\bf References}. Arrange the references alphabetically
by first author, rather than by order of occurrence in the text.
Provide as complete a citation as possible, using a consistent format,
such as the one for {\em Computational Linguistics\/} or the one in the 
{\em Publication Manual of the American 
Psychological Association\/}~\cite{APA:83}.  Use of full names for
authors rather than initials is preferred.  A list of abbreviations
for common computer science journals can be found in the ACM 
{\em Computing Reviews\/}~\cite{ACM:83}.

\subsection{Footnotes}

{\bf Footnotes}: Put footnotes at the bottom of the page and use 9
points text. They may be numbered or referred to by asterisks or other
symbols.\footnote{This is how a footnote should appear.} Footnotes
should be separated from the text by a line.\footnote{Note the line
separating the footnotes from the text.}

\subsection{Graphics}

{\bf Illustrations}: Place figures, tables, and photographs in the
report near where they are first discussed, rather than at the end, if
possible.  Wide illustrations may run across both columns.

{\bf Captions}: Provide a caption for every illustration; number each one
sequentially in the form:  ``Figure 1. Caption of the Figure.'' ``Table 1.
Caption of the Table.''  Type the captions of the figures and 
tables below the body, using 11 point text.

\section{Preprocessing}
The dataset we work with was formed in the TMX format. It was a dataset of 5.6 GB size. Thus, in order to work with it, we needed to divide the dataset into chunks or use samples we extract from it. Furthermore, we decided that while the TMX format might have its benefits, we did not need most of the perks it has. Therefore, we converted the dataset into a pickle, which enabled us to store it as python objects. Finally, we realized that our model required some normalization on each sentence via punctuation removal and lowercasing each word.

\subsection{Format Handling and Dividing the Dataset}
As mentioned above, our dataset was too large to read all of it at once. Therefore, after experimenting with a couple of methods, we decided to use basic file-streaming to read, process and save chunks of the dataset. After deciding on an approximate size for each chunk, which was roughly 500 MB's, we created a pipeline. Simply put, the pipeline took a chunk, cleared the irrelevant tags off of it, grabbed each English-Dutch sentence pair with a regex. The pipeline treated possibilities like half of a line being in another chunk or the translation of a line being in another chunk. Furthermore, it paired each sentence with its translation, put the pair in a list, and pickled the list in a file. This way, we acquired clean sentence pairs in different chunks, which we can read one by one from the pickle file. Finally, we created a function to read chunks from a pickle for easy usage.

\subsection{Sampling}
The developing process of models required small samples from the dataset to see the efficiency and quality of the model in a rough manner, before a proper evaluation process. However, just taking a chunk of the dataset would result with a high variation of low amounts of data. Therefore, we created a sampling function, which uses a preset of rules and extracts sentence pairs fitting that rule, then pickles them in another file for usage. This way, the accuracy of the model can be observed faster without an evaluation model on early stages. Also, we cleared the dataset off of some punctuation and transformed uppercase letters to lowercase. This was done to fit our dataset better for our model and remove irrelevant information.

\section{The RNN Encoder-Decoder model}
While regular neural networks are a powerful tool to train a model, they have one important limitation: they only take inputs of fixed length, and produce outputs of fixed lengths. For the translation of a sequence of words from English to Dutch this is not very useful, because both the length of the input and output sequence will vary between different sentences. We want to train a model that can take in any sentence of arbitrary length, and produce a corresponding translation. The solution to train this kind of model is provided by Recurrent Neural Networks (Bahdanau, 2014) (Sutskever, 2014) (Cho, 2014). 

\subsection{Encoder-Decoder}
An RNN can take in a sequence of any length, and produce any desired output. The key element to do this is the hidden state. To work with an input sequence $\textbf{x} = (x_1,x_2,…,x_t)$, the RNN looks at the elements of the input step by step. In our case, the input is a sentence, and the elements are words. Beginning at the first word, the RNN creates a hidden state, and an output vector y. For each next word, the RNN looks at that word and the previous hidden state, and updates to a new hidden state by
\begin{center}
    $\textbf{h}_{(t)} = f(\textbf{h}_{(t-1)},x_{t})$,
\end{center} 
where f can be any non-linear activation function. After the final word $x_t$ has been evaluated, we have the final output vector $y$, also called context vector. This is the first half of the model, or the Encoder. In this step, the meaning of the English input sentence gets encoded into a vector, thus we have a numerical representation of the input.
\\In the second step, we decode the context vector into a sentence in Dutch, again by using an RNN. The approach is very similar, just the other way round. The initial hidden state of the decoder is the context vector, and its first input is the <SOS> (start of sentence) token. At this first step, the decoder also creates its own hidden state. From there, it generates each new word of the output sequence, by looking at its previous output, the context vector, and its own hidden state. Thus the activation function for the decoder looks a bit different: 
\begin{center}
    $\textbf{h}_t = f(\textbf{h}_{(t-1)},y_{t-1},\textbf{c})$
\end{center} 
Finally, it will output a generated sentence in Dutch.

\subsection{Training}
During the training of the model, both these RNN’s are jointly trained via gradient-descent. The goal of the training is to maximize the probability that our model assigns to each Dutch sentence, given each English sentence. 
\begin{center}
    $max \frac{1}{N} \sum_{n=1}^{N} logp_{\theta}(y_n|x_n)$
\end{center}
The sentences $y_{n}$ and $x_{n}$ are those that we have from the data. The probability depends on the parameters theta of our model, and is logarithmic for easier summation and to stay within computational bounds.
\\We used \href{https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html}{an implementation from a PyTorch tutorial} (PyTorch, 2017) as the basis for our model. First we spend time understanding the code and we have a good general idea of what is going on in each part. Then we looked into adapting the code to our needs, and have it fit to our dataset. We were able to interact with the code in various places as well, to implement some tweaks to the model, as discussed in the next section.

\subsection{Changes to the model}
When implementing the changes to the model we used a small sample from the dataset with sentences that are similar in grammar. We looked at the BLEU score computed after evaluating the trained model, which was compared to the one for the base model: 0.01850195563099788. We implemented and evaluated the following changes/tweaks to the PyTorch implementation:

\subsubsection*{Attention}
Score: 0.025010259173115005
\\When using a regular decoder, the output vector from the encoder is all the decoder has to learn from and to base its translation on. This means the full input sentence and its meaning is now represented by one vector only.
\\When using a decoder with attention mechanism, however, for each word that the decoder outputs, it is provided with a set of attention weights, computed by the encoder. These weights tell the decoder which parts of the input vector are important to translate the word, for example a noun will be important information for translating the article that comes before it. This set of attention weights will be multiplied with the output vector from the encoder, to create a vector of weighted inputs for the decoder. The maximum length of the input sentences, output vectors for the encoder, needs to be specified before training the model, to make sure the set of weights has the right length for the longest sentence or sentences in the data. For shorter sentences not all weights will be used (PyTorch, 2017) (Bahdanau, 2014). 

\subsubsection*{Teacher Forcing}
Score: 0.046145425840054884
\\Teacher forcing is used in training the model, where instead of the last output from the decoder, on which the decoder would usually base its next prediction, the target tensor is fed to the decoder. As a result of this, translations that were made using teacher forcing have correct grammar, but are usually very different in meaning from the correct translation. Since the model is used to getting the first few words provided by the teacher, when it does not get these in the evaluation phase it does not know how to starting creating the output sentence (PyTorch, 2017) (Jaeger, 2002).

\subsubsection*{Reversing the input}
Score: 0.02149697704632642
\\Reversing the input (source) sentences when feeding them to the model to train has proven by \newcite{Sutskever:2014} to decrease the distance between words in the source and in the target language. In other words, long-term dependencies are being replaced by short-term dependencies. This results in a higher probability of two words, each from a different language, which context is depended on each other to be close in distance.

\subsubsection*{Activation functions}
Score: 0.0
\\At first we tried to implement the log sigmoid and leaky relu activation functions, but in the original log softmax activation function a dimension was specified, which could not be specified for the log sigmoid and leaky relu activation functions. This had as a result that the output sentences did not show any signs of the model having trained, but instead only contained sequences of the word 'ik' and 'ik ben', apparently the only words the model had learned.
\\Since this did not work out we tried using activation functions for which the dimension could be specified, namely the softmax and softmin activation functions. For these functions, however, the output sentences for each input consisted of similar words, and all output sentences were of the maximum length specified for the input and output sentences. Even training with more iterations did not change this. We think that the fact that no other activation function worked has to do with the way the model from the PyTorch implementation was set up, and that trying different activation functions is justified from a theoretical viewpoint (PyTorch, 2017).

\subsubsection*{Different NN units}
We considered changing the linear units that make up the RNN in the Pytorch implementation into RNN or LSTM units, but since Pytorch created a custom RNN from the linear unit specific for this implementation, it did not work and did not make sense to change the linear unit.

\subsubsection*{}
We have decided to implement all the changes that improved the evaluation score, which were the attention mechanism, teacher forcing, and reversing the input sentences.

\section{Evaluation}
To evaluate the performances of our model we chose to write our own implementation of the widely used BLEU score. The BLEU score takes all the n-grams up until the specified n and calculates the amount of similarities between two sentences, where for each n-gram each word can only be used once to count towards a match with the other sentence. To calculate the BLEU score over a set of sentences, the geometric mean of the scores for each individual sentence is used (Papineni, 2002).

\begin{thebibliography}{}

\bibitem[\protect\citename{Bahdanau \bgroup et al.\egroup}2014]{Bahdanau:2014}
D. Bahdanau, K. Cho, Y. Bengio.
\newblock 2014.
\newblock {\em Neural machine translation by jointly learning to align and translate.}
\newblock Retrieved from the arXiv database.

\bibitem[\protect\citename{Cho \bgroup et al.\egroup}2014]{Cho:2014}
K. Cho, B. van Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, Y. Bengio.
\newblock 2014.
\newblock {\em Learning phrase representations using RNN encoder-decoder for statistical machine translation.}
\newblock Retrieved from the arXiv database.

\bibitem[\protect\citename{Jaeger}2002]{Jaeger:2002}
H. Jaeger.
\newblock 2002.
\newblock {\em A tutorial on training recurrent neural networks, covering BPPT, RTRL, EKF and the "echo state network" approach}

\bibitem[\protect\citename{Papineni \bgroup et al.\egroup}2002]{Papineni:2002}
K. Papineni, S. Roukos, T. Ward, W. Zhu.
\newblock 2002
\newblock {\em BLEU: a Method for Automatic Evaluation of Machine Translation}
\newblock Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL)

\bibitem[\protect\citename{PyTorch}2017]{PyTorch:17}
\newblock {\em NLP From Scratch: Translation with a Sequence to Sequence Network and Attention}

\bibitem[\protect\citename{Sutskever \bgroup et al.\egroup}2014]{Sutskever:2014}
I. Sutskever, O. Vinyals, Q. Le.
\newblock 2014.
\newblock {\em Sequence to sequence learning with neural networks.}
\newblock Retrieved from the arXiv database.

\end{thebibliography}

\end{document}
