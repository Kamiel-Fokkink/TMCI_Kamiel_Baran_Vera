{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Notebook\n",
    "\n",
    "This notebook is dedicated to the preprocessing of the data. The input file is in the format of an .tmx file. The steps that are currently being done are:\n",
    "1. Extract lines\n",
    "2. Store surplus\n",
    "3. Pair lines\n",
    "4. Clear punctuation\n",
    "5. Sample the dataset\n",
    "\n",
    "## Imports\n",
    "Below are all the libraries used for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "This function includes all cleaning steps of the data. It reads the tmx file, takes out the lines that interest the model, removes unnecessary tags, and pairs the lines as englist-dutch respective order. Afterwards, it writes the data in a pickle for further usage. A pickle reading function with an optional limiter has also been included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def clean(input_location: str, output_location: str, chunk_size = 1048576):\n",
    "    \"\"\" This function takes a file, reads it, separates it, and saves it\n",
    "    to a document via pickling it. Chunk size means the number of characters\n",
    "    which roughly converts to the amount of bytes. Default setting is equal to a\n",
    "    Megabyte. \"\"\"\n",
    "    \n",
    "    # Opening the filestreams\n",
    "    input_file = open(input_location, \"r\")\n",
    "    output_file = open(f\"data/{output_location}\", \"wb\")\n",
    "    \n",
    "    # Reading the first chunk\n",
    "    chunk = input_file.read(chunk_size)\n",
    "    \n",
    "    waiting_single = [[], []]              # Variable to hold the line pairs\n",
    "    extra = \" \"                            # Variable to hold extra strings\n",
    "    \n",
    "    while chunk:\n",
    "        #print(chunk+extra+\"\\n\\n\")\n",
    "        lines, extra = getLines(extra + chunk)\n",
    "        #print(f\"{lines}\\n{extra}\")\n",
    "        if not lines:\n",
    "            chunk = input_file.read(chunk_size)\n",
    "            continue\n",
    "        waiting_single, pairs = pair(waiting_single, lines)\n",
    "        pickle.dump(pairs, output_file)\n",
    "        chunk = input_file.read(chunk_size)\n",
    "    input_file.close()\n",
    "    output_file.close()\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def pair(temp: list, lines: list) -> list:\n",
    "    \"\"\" Takes two list, one with all the unpaired lines, and a list with possibly an\n",
    "    unpaired single and a tag. \"\"\"\n",
    "    \n",
    "    results = list()\n",
    "    for tag, line in lines:\n",
    "        if len(temp[0]) == 2 and f\"{temp[1][0]}{temp[1][1]}\" != \"ennl\":\n",
    "            # If the pair is wrongly ordered\n",
    "            print(temp)\n",
    "            print(results)\n",
    "            raise Exception(\"Line mismatch occured\")\n",
    "        elif len(temp[0]) == 2:\n",
    "            # If the pair is correct\n",
    "            results.append(copy.copy(temp[0]))\n",
    "            temp = [[],[]]\n",
    "        # The part which adds a line to be paired\n",
    "        temp[0].append(line)\n",
    "        temp[1].append(tag)\n",
    "    return (temp, results)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def getLines(temp_str: str) -> (list, str):\n",
    "    \"\"\" Takes a string, extracts the lines with actual quotes.\n",
    "    Returns the lines and the string left after the last line. \"\"\"\n",
    "    \n",
    "    lines = re.findall(r\"<tuv.+?(?=</seg>)</seg>\", temp_str)\n",
    "    # If there is no lines to find, pass the string as a whole\n",
    "    if not lines:\n",
    "        return [[], temp_str]\n",
    "    # If there is a line, this part extracts the text after\n",
    "    # the last scanned line\n",
    "    if lines[-1] != temp_str[-len(lines[-1]):]:\n",
    "        remnants = \"\"\n",
    "        for i in range(1, len(temp_str)-len(lines[-1])):\n",
    "            if lines[-1] == temp_str[-(len(lines[-1])+i):-i]:\n",
    "                break\n",
    "            else:\n",
    "                remnants += temp_str[-i]\n",
    "    # Erases the parts we are not interested in\n",
    "    lines = [(line[15:17], line[24:-6]) for line in lines]\n",
    "    return (lines, remnants[::-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def readPickle(pickle_off: str, limiter = -1):\n",
    "    \"\"\" Read the pickle either in a limited amount of chunks or all\n",
    "    of them at once. \"\"\"\n",
    "    objects = []\n",
    "    file_stream = open(pickle_off, \"rb\")\n",
    "    while limiter != 0:\n",
    "        try:\n",
    "            objects.append(pickle.load(file_stream))\n",
    "            limiter -= 1\n",
    "        except EOFError:\n",
    "            break\n",
    "    file_stream.close()\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def processPickle(pickle_off: str, process=lambda x:x, limiter = -1, store=False):\n",
    "    \"\"\" Takes in a pickle, reads it in chunks and applies the process function to it in each chunk.\n",
    "    Depending on the store value, it either stores the results in a list and returns it or returns nothing.\n",
    "    The process function can only have one input which is the read object from the pickle. \"\"\"\n",
    "    \n",
    "    objects = []\n",
    "    file_stream = open(pickle_off, \"rb\")\n",
    "    \n",
    "    while limiter != 0:\n",
    "        try:\n",
    "            if store:objects.append(process(pickle.load(file_stream)))\n",
    "            else:process(pickle.load(file_stream))\n",
    "            limiter -= 1\n",
    "        except EOFError: # When there is nothing else to read\n",
    "            break\n",
    "    file_stream.close()\n",
    "    if store: return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLen(lines: list)->int:\n",
    "    \"\"\" Takes a list of lines, prints and returns the length. \"\"\"\n",
    "    l = len(lines)\n",
    "    print(f\"The length of this chunk is {l} lines\")\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of this chunk is 83064 lines\n",
      "The length of this chunk is 75154 lines\n",
      "The length of this chunk is 77409 lines\n",
      "The length of this chunk is 95147 lines\n",
      "The length of this chunk is 84284 lines\n",
      "The length of this chunk is 81818 lines\n",
      "The length of this chunk is 74158 lines\n",
      "The length of this chunk is 71400 lines\n",
      "The length of this chunk is 75132 lines\n",
      "The length of this chunk is 77556 lines\n",
      "The length of this chunk is 49404 lines\n",
      "The total length of pickle is 844526 lines\n"
     ]
    }
   ],
   "source": [
    "# In order to get the full length of a pickle, we do\n",
    "full_l = sum(processPickle(\"data/sample0.pkl\",process = getLen, store = True))\n",
    "print(f\"The total length of pickle is {full_l} lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# The pattern to tokenize each sentence\n",
    "pattern = r'''(?x)           # set flag to allow verbose regexps\n",
    "     (?:[A-Z]\\.)+            # abbreviations, e.g. U.S.A.\n",
    "   | \\w+(?:[-']\\w+)*[,:;']?  # words with optional internal hyphens\n",
    "'''\n",
    "\n",
    "def cleanPunc(line: str) -> list:\n",
    "    \"\"\" Takes a string, makes all of them lowercase and tokenizes it, getting rid of unwanted characters. \"\"\"\n",
    "    return nltk.regexp_tokenize(line.lower(), pattern)\n",
    "\n",
    "def samplingDataset(line_pairs: list, sampleCheck) -> list:\n",
    "    \"\"\" Takes a list of tokenized pairs, and a function to check one of the tokenized lists.\n",
    "    Extracts the ones that return true for the check. \"\"\"\n",
    "    sample = list()\n",
    "    for en, nl in line_pairs:\n",
    "        temp_en = cleanPunc(en)\n",
    "        temp_nl = cleanPunc(nl)\n",
    "        if sampleCheck(temp_en):\n",
    "            sample.append([\" \".join(temp_en), \" \".join(temp_nl)])\n",
    "    return sample\n",
    "\n",
    "def samplingMethod1(line: list) -> bool:\n",
    "    \"\"\" Takes in a list of strings. Checks if it has the given words in given indexes depending on\n",
    "    the list. \"\"\"\n",
    "    \n",
    "    # This list is formed of lists of an index and the possible words that are supposed to be\n",
    "    # in that index\n",
    "    check_list = [[0, [\"he\", \"she\", \"it\"]], [1, [\"is\"]]]\n",
    "    \n",
    "    for index, words in check_list:\n",
    "        if len(line) > check_list[-1][0] and line[index] not in words:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def pickleSample(output_location: str, sampleCheck=lambda x:True):\n",
    "    \"\"\" Takes in an output location, and a function to apply sampling with. Uses the process pickle\n",
    "    function to chunk the pickle and apply the sampling in each chunk. Then writes the cumulative\n",
    "    result to a new pickle. \"\"\"\n",
    "    output_file = open(f\"data/{output_location}\", \"wb\")\n",
    "    processPickle(\"data/en_nl_line_pairs.pkl\",\n",
    "                  process=lambda x:pickle.dump(samplingDataset(x, samplingMethod1), output_file))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "pickleSample(\"sample0.pkl\", sampleCheck=samplingMethod1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
